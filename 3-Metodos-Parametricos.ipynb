{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aprendizaje Computacional  \n",
    "\n",
    "## Mario Graff (mgraffg@ieee.org, mario.graff@infotec.mx)  \n",
    "## [https://github.com/ingeotec](https://github.com/ingeotec)\n",
    "## [https://github.com/mgraffg](https://github.com/mgraffg)\n",
    "## CONACYT - INFOTEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Temas  \n",
    "\n",
    "1. Introducción  \n",
    "2. Aprendizaje supervisado  \n",
    "3. Métodos paramétricos  \n",
    "4. Métodos no-paramétricos  \n",
    "5. Máquinas de kernel  \n",
    "6. Métodos no convencionales de aprendizaje  \n",
    "7. Diseño y análisis de experimentos de aprendizaje  \n",
    "8. Aplicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Métodos Paramétricos  \n",
    "\n",
    "3.1. Teoría Bayesiana de Decisión  \n",
    "3.2. Clasificación  \n",
    "3.3. Máxima Verosimilitud  \n",
    "3.4. Funciones de probabilidad  \n",
    "3.5. Clasificación de texto  \n",
    "3.6. Bayes Ingenuo  \n",
    "3.7. Discriminación Linea  \n",
    "3.8. Regresión  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Teoría Bayesiana de Decisión\n",
    "\n",
    "* Variables no observadas  \n",
    "  $r = f(x)$\n",
    "* En general no es posible  \n",
    "* Modela un volado como:  \n",
    "  * $P(X=cara) = 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Suponiendo que existe una función determinista $f$ que genera $r = f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clasificación\n",
    "\n",
    "* Un problema de clasificación se puede modelar como:  \n",
    "  $P(C \\mid x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$P(C \\mid x)$ es la probabilidad de $C$ dada la entrada $x$. Suponiendo $K$ clases\n",
    "se sabe $P(C = 1 \\mid x) + P(C = 2 \\mid x) + \\ldots + P(C = K \\mid x) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Utilizando el teorema de Bayes  \n",
    "  $P(C \\mid x) = \\frac{P(x \\mid C) P(C)}{P(x)}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * $P(C \\mid x)$ probabilidad posterior _posterior probability_\n",
    "  * $P(C)$ probabilidad previa _prior probability_  \n",
    "  * $P(x \\mid C)$ probabilidad de clase _class likelihood_\n",
    "  * $P(x)$ evidencia _evidence_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * $P(x) = \\sum_C P(x, C) = \\sum_C P(x \\mid C)P(C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * $P(x) = P(x \\mid C=1) P(C=1) + P(x \\mid C=0) P(C=0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Clasificación (2)\n",
    "\n",
    "* $P(C_i \\mid x) = \\frac{P(x \\mid C_i) P(C_i)}{P(x)}$\n",
    "* El objeto $x$ pertenece a la clase  \n",
    "  $k = \\text{argmax}_i P(C_i \\mid x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Funciones de decisión  \n",
    "  $g_i(x) = P(C_i \\mid x)$\n",
    "* Equivalente  \n",
    "  $g_i(x) = P(x \\mid C_i) P(C_i)$  \n",
    "* Para dos clases se puede  \n",
    "  $g(x) = g_1(x) - g_2(x)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimador de Máxima Verosimilitud -  _Maximum Likelihood Estimation_\n",
    "\n",
    "* $x_i \\sim P(x \\mid \\theta)$\n",
    "* Verosimilitud $l(\\theta \\mid \\mathcal X)$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $l(\\theta \\mid \\mathcal X) \\equiv P(\\mathcal X \\mid \\theta)$\n",
    "* Dado que son iid.  \n",
    "  $P(\\mathcal X \\mid \\theta) = \\prod_i P(x_i \\mid \\theta)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathcal L(\\theta \\mid \\mathcal X) = \\log l(\\theta \\mid \\mathcal X) = \\sum_i \\log P(x_i \\mid \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bernoulli  \n",
    "\n",
    "* $p = P(x=1)$\n",
    "* $P(x) = p^x (1 - p)^{1-x}$  \n",
    "  $x \\in \\{0, 1\\}$\n",
    "* $\\theta = p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $l(p \\mid \\mathcal X) = P(\\mathcal X \\mid p) = \\prod_i p^{x_i} (1 - p)^{1-x_i}$  \n",
    "* $\\mathcal L(p \\mid \\mathcal X) = \\sum_i \\log p^{x_i} (1 - p)^{1-x_i}$\n",
    "* $ = \\sum_i ( \\log p^{x_i} + \\log (1 - p)^{1-x_i}) = \\sum_i x_i \\log p + \\sum_i (1- x_i) \\log (1 - p)$\n",
    "* $ = \\sum_i x_i \\log p + (N - \\sum_i x_i) \\log (1 - p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\hat{p} = \\frac{\\partial \\mathcal L(p \\mid \\mathcal X)}{\\partial p}$\n",
    "* $\\hat{p} = \\frac{\\sum_i x_i}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bernulli multiples variables\n",
    "\n",
    "* $\\mathbf x = (x_1, x_2, \\ldots, x_d)$  \n",
    "  donde $x_i = \\{0, 1\\}$\n",
    "* $P(\\mathbf x \\mid C_i) = \\prod_j^d P(x_j = 1 \\mid C_i)^{x_j} (1 - P(x_j = 1 \\mid C_i))^{1-x_j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $P(x_j = 1 \\mid C_i) = \\frac{\\sum_{\\mathbf w, r \\in \\mathcal X} \\delta(C_i = r) \\delta(w_j)}{\\sum_{\\mathbf w, r \\in \\mathcal X} \\delta(C_i = r)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $P(C_i \\mid \\mathbf x) = \\frac{P(\\mathbf x \\mid C_i) P(C_i)}{P(\\mathbf x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathbf x$ es la clase  \n",
    "  $\\text{argmax}_i P(C_i \\mid \\mathbf x) = \\text{argmax}_i \\log P(C_i \\mid \\mathbf x)$\n",
    "* $ = \\text{argmax}_i \\log P(\\mathbf x \\mid C_i) + \\log P(C_i) - \\log P(\\mathbf x)$\n",
    "* $ = \\text{argmax}_i \\log P(\\mathbf x \\mid C_i) + \\log P(C_i)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $ = \\text{argmax}_i \\log P(C_i) + \\sum_j^d \\log P(x_j = 1 \\mid C_i)^{x_j} (1 - P(x_j = 1 \\mid C_i))^{1-x_j}$\n",
    "* $= \\text{argmax}_i \\log P(C_i) + \\sum_j^d x_j \\log P(x_j = 1 \\mid C_i) + (1-x_j) \\log (1 - P(x_j = 1 \\mid C_i))$\n",
    "* $ = \\text{argmax}_i  \\sum_j^d x_j w_j^i + (1-x_j) v_j^i + z_i$\n",
    "* $z_i = \\log P(C_i)$\n",
    "* $w_j^i = \\log P(x_j = 1 \\mid C_i)$\n",
    "* $v_j^i = \\log (1 - P(x_j = 1 \\mid C_i))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Clasificación de Texto con Bernulli\n",
    "\n",
    "* Una manera muy simple es ver un documento como una bolsa de palabras\n",
    "* Hoy es un día feliz\n",
    "* La la computadora\n",
    "* Feliz de tener una computadora\n",
    "* Fallo una computadora\n",
    "\n",
    "|la  |computadora|feliz|hoy|es|un|día|de|tener|una|fallo|  \n",
    "|---:|----------:|----:|--:|-:|-:|--:|-:|----:|--:|----:|  \n",
    "|0   |0          |1    |1  |1 |1 |1  |0 |0    |0  |0    |\n",
    "|1   |1          |0    |0  |0 |0 |0  |0 |0    |0  |0    |\n",
    "|0   |1          |1    |0  |0 |0 |0  |1 |1    |1  |0    |\n",
    "|0   |1          |0    |0  |0 |0 |0  |0 |0    |1  |1    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Clases\n",
    "\n",
    "* Hoy es un día feliz - Positivo\n",
    "* La la computadora - Neutro\n",
    "* Feliz de tener una computadora - Positivo\n",
    "* Fallo una computadora - Negativo\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Clase Positiva\n",
    "\n",
    "* Hoy es un día feliz - Positivo\n",
    "* Feliz de tener una computadora - Positivo\n",
    "\n",
    "* $w_j^i = \\log P(x_j = 1 \\mid C_i)$\n",
    "\n",
    "|la  |computadora|feliz|hoy|es|un|día|de|tener|una|fallo|     |\n",
    "|---:|----------:|----:|--:|-:|-:|--:|-:|----:|--:|----:|----:|\n",
    "|0   |0          |1    |1  |1 |1 |1  |0 |0    |0  |0    |     |\n",
    "|0   |1          |1    |0  |0 |0 |0  |1 |1    |1  |0    |     |\n",
    "|0   |0.5        |1    |0.5|0.5|0.5|0.5|0.5|0.5|0.5|0   |$P(x_j=1 \\mid C_i)$  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Clase Positiva (2)\n",
    "\n",
    "* Fallo una computadora\n",
    "* $P(\\mathbf x \\mid C_i) = \\prod_j^d P(x_j = 1 \\mid C_i)^{x_j} (1 - P(x_j = 1 \\mid C_i))^{1-x_j}$\n",
    "\n",
    "|la  |computadora|feliz|hoy|es|un|día|de|tener|una|fallo|    |  \n",
    "|---:|----------:|----:|--:|-:|-:|--:|-:|----:|--:|----:|---:|  \n",
    "|0   |1          |0    |0  |0 |0 |0  |0 |0    |1  |1    |$\\mathbf x$|\n",
    "|0   |0.5        |1    |0.5|0.5|0.5|0.5|0.5|0.5|0.5|0   |$P(x_j=1 \\mid C_i)$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Laplacean prior\n",
    "* $P(x_j = 1 \\mid C_i) = \\frac{1 + \\sum_{\\mathbf w, r \\in \\mathcal X} \\delta(C_i = r) \\delta(w_j)}{d + \\sum_{\\mathbf w, r \\in \\mathcal X} \\delta(C_i = r)} $  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Actividad\n",
    "\n",
    "Crear un clasificador por lenguaje, que dado un texto determine su polaridad dentro de 7 clases que corresponden a diferentes niveles de positividad y negatividad del texto.\n",
    "\n",
    "* 3 - Muy positivo\n",
    "* 2 - Moderadamente positivo\n",
    "* 1 - Poco positivo\n",
    "* 0 - Neutro\n",
    "* -1 - Poco negativo\n",
    "* -2 - Moderadamente negativo\n",
    "* -3 - Muy negativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pasos\n",
    "\n",
    "* Leer la descripción de la tarea Task 1 - V-oc de [SemEval 2018 Task 1](https://competitions.codalab.org/competitions/17751#learn_the_details-overview)\n",
    "* Bajar de [SemEval 2018 Task 1 Dataset](https://competitions.codalab.org/competitions/17751#learn_the_details-datasets) los datos correspondientes a V-oc  \n",
    "  * English   \n",
    "    * Training set  \n",
    "    * Development set\n",
    "    * Test set\n",
    "  * Arabic   \n",
    "    * Training set  \n",
    "    * Development set\n",
    "    * Test set\n",
    "  * Spanish   \n",
    "    * Training set  \n",
    "    * Development set\n",
    "    * Test set      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pasos (2)\n",
    "\n",
    "Recuerden, los datos que acaban de bajar no pueden ser utilizados con fines comerciales.\n",
    "\n",
    "* Combinar por cada idioma los archivos _Training set_ y _Development set_  \n",
    "  este es su conjunto $\\mathcal X$\n",
    "* El conjunto _Test set_ es $\\mathcal P$\n",
    "* Utilizar $\\mathcal X$ para obtener $w_j^i$, $v_j^i$, y $z_i$ de  \n",
    "  $\\text{argmax}_i  \\sum_j^d x_j w_j^i + (1-x_j) v_j^i + z_i$\n",
    "* Predecir $\\mathcal P$ con el modelo anterior  \n",
    "* Medir el rendimiento de su clasificador usando:  \n",
    "  * macro-F1  \n",
    "  * accuracy  \n",
    "  * macro-Recall  \n",
    "  * macro-Precision\n",
    "  * Ver [scikit-learn metrics](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)\n",
    "* Enviar un reporte con los resultados (una hoja)\n",
    "* Enviar el código de su clasificador  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multinomial\n",
    "\n",
    "* Tamaño del vocabulario $d$.\n",
    "* $\\mathbf x$ es un documento\n",
    "* $\\mathbf x \\in \\mathbb R^d$\n",
    "* $P(C_i \\mid \\mathbf x) = \\frac{P(\\mathbf x \\mid C_i) P(C_i)}{P(\\mathbf x)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $P(\\mathbf x \\mid C_i) = (\\sum_j x_j)! \\prod_j \\frac{p(x_j \\mid C_j)^{x_j}}{x_j!}$\n",
    "* Bernulli  \n",
    "  * $P(\\mathbf x \\mid C_i) = \\prod_j^d P(x_j = 1 \\mid C_i)^{x_j} (1 - P(x_j = 1 \\mid C_i))^{1-x_j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $P(x_j \\mid C_i) = \\frac{1 + \\sum_{\\mathbf w, r \\in \\mathcal X} \\delta(C_i = r) w_j}{d + \\sum_k^d \\sum_{\\mathbf w, r \\in \\mathcal X} \\delta(C_i = r) w_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $P(\\mathbf x \\mid C_i) = (\\sum_j x_j)! \\prod_j \\frac{p(x_j \\mid C_j)^{x_j}}{x_j!}$\n",
    "* $(\\sum_j x_j)!$ y $\\prod_j x_j!$\n",
    "* $P(\\mathbf x \\mid C_i) \\propto \\prod_j p(x_j \\mid C_j)^{x_j}$\n",
    "* $P(C_i \\mid \\mathbf x) = \\frac{P(\\mathbf x \\mid C_i) P(C_i)}{P(\\mathbf x)}$\n",
    "* $P(C_i \\mid \\mathbf x) \\propto \\prod_j p(x_j \\mid C_j)^{x_j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Clasificación de Texto con Multinomial\n",
    "\n",
    "* Una manera muy simple es ver un documento como una bolsa de palabras\n",
    "* Hoy es un día feliz\n",
    "* La la computadora\n",
    "* Feliz de tener una computadora\n",
    "* Fallo una computadora\n",
    "\n",
    "|la  |computadora|feliz|hoy|es|un|día|de|tener|una|fallo|  \n",
    "|---:|----------:|----:|--:|-:|-:|--:|-:|----:|--:|----:|  \n",
    "|0   |0          |1    |1  |1 |1 |1  |0 |0    |0  |0    |\n",
    "|2   |1          |0    |0  |0 |0 |0  |0 |0    |0  |0    |\n",
    "|0   |1          |1    |0  |0 |0 |0  |1 |1    |1  |0    |\n",
    "|0   |1          |0    |0  |0 |0 |0  |0 |0    |1  |1    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $P(x_j \\mid C_i) = \\frac{1 + \\sum_{\\mathbf w, r \\in \\mathcal X} \\delta(C_i = r) w_j}{d + \\sum_k^d \\sum_{\\mathbf w, r \\in \\mathcal X} \\delta(C_i = r) w_k}$\n",
    "\n",
    "|la  |computadora|feliz|hoy|es|un|día|de|tener|una|fallo|     |\n",
    "|---:|----------:|----:|--:|-:|-:|--:|-:|----:|--:|----:|----:|\n",
    "|0   |0          |1    |1  |1 |1 |1  |0 |0    |0  |0    |     |\n",
    "|0   |1          |1    |0  |0 |0 |0  |1 |1    |1  |0    |     |\n",
    "|0   | $\\frac{1 + 1}{d + 10}$ | $\\frac{1 + 2}{d + 10}$   |-|-|-|-|-|-|-|- |$P(x_j \\mid C_i)$  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Actividad\n",
    "\n",
    "* Implementar un algoritmo de clasificación utilizando _Multinomial_\n",
    "* Medir el rendimiento utilizando\n",
    "  * macro-F1  \n",
    "  * accuracy  \n",
    "  * macro-Recall  \n",
    "  * macro-Precision\n",
    "* Comparar los resultados con los obtenidos utilizando _Bernulli_  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Distribución Normal\n",
    "\n",
    "* Las entradas $\\mathbf x \\in \\mathbb R^d$\n",
    "* $P(C_i \\mid \\mathbf x) = \\frac{P(\\mathbf x \\mid C_i) P(C_i)}{P(\\mathbf x)}$\n",
    "* $P(\\mathbf x) = \\frac{1}{ (2 \\pi)^{\\frac{d}{2}} \\mid \\Sigma \\mid ^{\\frac{1}{2}}} \\exp{-\\frac{1}{2} (\\mathbf x - \\mathbf \\mu)' \\Sigma^{-1} (\\mathbf x - \\mathbf \\mu)}$\n",
    "* Bayes Ingenuo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Bayes Ingenuo _Naive Bayes_\n",
    "\n",
    "* $P(\\mathbf x) = \\prod_i^d p_i(x_i)$\n",
    "* $P(\\mathbf x) = \\frac{1}{ (2 \\pi)^{\\frac{d}{2}} \\prod_i^d \\sigma_i} \\exp{-\\frac{1}{2} \\sum_i^d (\\frac{x_i - \\mu_i}{\\sigma_i})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pos = np.random.multivariate_normal([0, 0.3], \n",
    "                                    [[0.3, 0.1], [0.1, 0.3]], size=100)\n",
    "neg = np.random.multivariate_normal([2.3, -0.3], \n",
    "                                    [[0.1, 0.01], [0.01, 0.3]], size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pylab.plot([x[0] for x in pos], [x[1] for x in pos], '*')\n",
    "pylab.plot([x[0] for x in neg], [x[1] for x in neg], '*')\n",
    "pylab.ylim(-2, 2)\n",
    "pylab.xlim(-2, 4)\n",
    "pylab.legend(['Positiva', 'Negativa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y = np.zeros(pos.shape[0] + neg.shape[0])\n",
    "y[:pos.shape[0]] = 1\n",
    "X = np.concatenate((pos, neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Sea $\\mathbf X$ el conjunto de entrenamiento\n",
    "* Sea $y$ la clase asociada\n",
    "* Entrenando un Bayes Ingenuo con _sklearn_\n",
    "\n",
    "```python   \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "m = GaussianNB().fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Predecir un conjunto no visto\n",
    "* Graficar los puntos clasificados incorrectamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "m = GaussianNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "posT = np.random.multivariate_normal([0, 0.3], \n",
    "                                     [[0.3, 0.1], [0.1, 0.3]], size=1000)\n",
    "negT = np.random.multivariate_normal([2.3, -0.3], \n",
    "                                     [[0.1, 0.01], [0.01, 0.3]], size=1000)\n",
    "pos_e = ~ (m.predict(posT) == 1)\n",
    "neg_e = ~ (m.predict(negT) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pos = posT[pos_e]\n",
    "neg = negT[neg_e]\n",
    "todos = np.concatenate((posT[~pos_e], negT[~neg_e]))\n",
    "pylab.ylim(-2, 2)\n",
    "pylab.xlim(-2, 4)\n",
    "pylab.plot([x[0] for x in todos], [x[1] for x in todos], '+')\n",
    "pylab.plot([x[0] for x in pos], [x[1] for x in pos], '*')\n",
    "pylab.plot([x[0] for x in neg], [x[1] for x in neg], '*')\n",
    "pylab.legend(['', 'Positiva', 'Negativa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Función de Decisión\n",
    "\n",
    "* $g(\\mathbf x) = g_2(\\mathbf x) - g_1(\\mathbf x)$\n",
    "* $ = P(C_2 \\mid \\mathbf x) - P(C_1 \\mid \\mathbf x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Se busca\n",
    "* $g(\\mathbf x) = P(C_2 \\mid \\mathbf x) - P(C_1 \\mid \\mathbf x) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def boundary(x, y, m):\n",
    "    px = []\n",
    "    py = []\n",
    "    for y0 in y:\n",
    "        pr = m.predict(np.vstack((x, [y0] * x.shape[0])).T)\n",
    "        df = np.fabs(pr[1:] - pr[:-1])\n",
    "        step = np.where(df > 0)[0]\n",
    "        if len(step):\n",
    "            for x0 in step:\n",
    "                py.append(y0)\n",
    "                px.append(x[x0])\n",
    "    return px, py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 4, 1000)\n",
    "y = np.linspace(-2, 2, 1000)\n",
    "px, py = boundary(x, y, m)\n",
    "pylab.ylim(-2, 2)\n",
    "pylab.xlim(-2, 4)\n",
    "pylab.plot(px, py, '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mvn = np.random.multivariate_normal\n",
    "klass_a = mvn([0, 1], [[0.3, 0.5], [0.1, 0.3]], size=1000)\n",
    "klass_b = mvn([2.3, 1], [[0.1, 0.01], [0.01, 0.3]], size=1000)\n",
    "klass_c = mvn([1, 0], [[0.5, 0.1], [0.01, 0.3]], size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pylab.ylim(-3, 4)\n",
    "pylab.xlim(-2, 4)\n",
    "for d in [klass_a, klass_b, klass_c]:\n",
    "    pylab.plot([x[0] for x in d], [x[1] for x in d], '*')\n",
    "pylab.legend(['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "for k, d in enumerate([klass_a, klass_b, klass_c]):\n",
    "    t = np.zeros(d.shape[0])\n",
    "    t[:] = k\n",
    "    y += t.tolist()\n",
    "m = GaussianNB().fit(np.concatenate((klass_a, klass_b, klass_c), axis=0), y)\n",
    "x = np.linspace(-2, 4, 1000)\n",
    "y = np.linspace(-4, 4, 1000)\n",
    "px, py = boundary(x, y, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pylab.ylim(-4, 4)\n",
    "pylab.xlim(-2, 4)\n",
    "for d in [klass_a, klass_b, klass_c]:\n",
    "    pylab.plot([x[0] for x in d], [x[1] for x in d], '.')\n",
    "pylab.plot(px, py, '+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Explique la función de decisión\n",
    "* Se puede mejorar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementación de Bayes Ingenuo\n",
    "\n",
    "* Sea $\\mathcal X$ el conjunto de entrenamiento\n",
    "* Parámetros  \n",
    "  * $\\sigma_i$\n",
    "  * $\\mu_i$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* En realidad son:  \n",
    "  * $\\sigma_i^c$  \n",
    "  * $\\mu_i^c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathcal C_c = \\{ (\\mathbf x, r) \\in \\mathcal X \\mid r = c \\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mu_i^c = \\frac{\\sum_{(\\mathbf x, r) \\in \\mathcal C_c} x_i}{\\mid \\mathcal C \\mid}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# En python cómo se hace\n",
    "\n",
    "* Utilizando numpy\n",
    "* Crear un problema\n",
    "* Variables independientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python   \n",
    "import numpy as np\n",
    "mvn = np.random.multivariate_normal\n",
    "klass_a = mvn([0, 1], [[0.3, 0.5], [0.1, 0.3]], size=1000)\n",
    "klass_b = mvn([2.3, 1], [[0.1, 0.01], [0.01, 0.3]], size=1000)\n",
    "klass_c = mvn([1, 0], [[0.5, 0.1], [0.01, 0.3]], size=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mvn = np.random.multivariate_normal\n",
    "klass_a = mvn([0, 1], [[0.3, 0.5], [0.1, 0.3]], size=1000)\n",
    "klass_b = mvn([2.3, 1], [[0.1, 0.01], [0.01, 0.3]], size=1000)\n",
    "klass_c = mvn([1, 0], [[0.5, 0.1], [0.01, 0.3]], size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Clases y conjunto $\\mathcal X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python  \n",
    "y = []\n",
    "for k, d in enumerate([klass_a, klass_b, klass_c]):\n",
    "    _ = np.zeros(d.shape[0])\n",
    "    _.fill(k)\n",
    "    y += _.tolist()\n",
    "X = np.concatenate((klass_a, klass_b, klass_c), axis=0)\n",
    "y = np.array(y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y = []\n",
    "for k, d in enumerate([klass_a, klass_b, klass_c]):\n",
    "    _ = np.zeros(d.shape[0])\n",
    "    _.fill(k)\n",
    "    y += _.tolist()\n",
    "X = np.concatenate((klass_a, klass_b, klass_c), axis=0)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Revolver el conjunto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python   \n",
    "index = np.arange(y.shape[0])\n",
    "np.random.shuffle(index)\n",
    "X = X[index]\n",
    "y = y[index]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "index = np.arange(y.shape[0])\n",
    "np.random.shuffle(index)\n",
    "X = X[index]\n",
    "y = y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $\\mathbf \\mu^c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python   \n",
    "mu_a = X[y == 0].mean(axis=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mu_a = X[y == 0].mean(axis=0)\n",
    "print(mu_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathbf \\sigma^c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python   \n",
    "std_a = X[y == 0].std(axis=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "std_a = X[y == 0].std(axis=0)\n",
    "print(std_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python   \n",
    "klass_a = mvn([0, 1], [[0.3, 0.5], [0.1, 0.3]], size=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Actividad\n",
    "\n",
    "* Graficar la función de decisión real del problema de 3 clases\n",
    "* Implementar un Bayes Ingenuo con distribución normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discriminante Lineal\n",
    "\n",
    "* Clases son linealmente separables  \n",
    "* $C = \\text{argmax}_j g_j (\\mathbf x)$  \n",
    "* Anteriormente $g_j(\\mathbf x) = \\log P(C_j | \\mathbf x)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Identificar directamente $g$\n",
    "* $g(\\mathbf x \\mid \\theta_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $g_i(\\mathbf x \\mid \\mathbf w_i, w_{i0}) = \\mathbf w_i \\cdot \\mathbf x + w_{i0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $g_i(\\mathbf x) = \\sum_j w_j \\phi_{ij} (\\mathbf x)$\n",
    "* Basis functions $\\phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\phi_{j,1}(\\mathbf x) = x_1^2$  \n",
    "* $\\phi_{j,2}(\\mathbf x) = x_1 \\cdot x_2$  \n",
    "* $\\phi_{j,3}(\\mathbf x) = x_2^2$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dos clases \n",
    "\n",
    "* Observando los valores de la clase\n",
    "* Es Bernoulli  \n",
    "$l(\\theta \\mid \\mathcal X) = \\prod_t (y_t)^{r_t} (1 - y_t)^{(1-r_t)}$\n",
    "* $l(\\theta \\mid \\mathcal X) = \\prod_{\\mathbf x, r \\in \\mathcal X} g(\\mathbf x \\mid \\theta)^r (1 - g(\\mathbf x \\mid \\theta))^{(1-r)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $E = - \\log l$\n",
    "* $E(\\theta \\mid \\mathcal X) = - \\sum_{\\mathbf x, r \\in \\mathcal X} r \\log g(\\mathbf x \\mid \\theta) + (1-r) \\log (1 - g(\\mathbf x \\mid \\theta))  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Regresión logística\n",
    "\n",
    "* $g(\\mathbf x \\mid \\mathbf w, w_0) = \\frac{1}{1 + \\exp{-(\\mathbf w \\cdot \\mathbf x + w_0)}}$\n",
    "* Cómo se puede obtener $\\mathbf w$ y $w_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Resolviendo el sistema de ecuaciones  \n",
    "  $\\frac{\\partial E}{\\partial \\mathbf w_i} = 0$ para $i=0 \\cdots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* No existe solución cerrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Descenso de gradiente  \n",
    "* Método de optimización iterativo\n",
    "* Definido para función derivable\n",
    "* Minimizar negativo del gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\theta_{n+1} = \\theta_n - \\nu \\nabla f(\\theta_n) $\n",
    "* Se require tener $\\nabla f(\\theta_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\nabla f(\\theta_n) \\equiv ( \\frac{\\partial E}{\\partial \\mathbf w_0}, \\frac{\\partial E}{\\partial \\mathbf w_1}, \\cdots)^{\\prime}$\n",
    "* $\\mathbf w_{n+1} = \\mathbf w_n - \\nu \\nabla E(\\mathbf w \\mid \\mathcal X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathbf w_{n+1} = \\mathbf w_n + \\nu \\nabla \\log l(\\mathbf w \\mid \\mathcal X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\log l(\\mathbf w \\mid \\mathcal X) = \\sum_{\\mathbf x, r \\in \\mathcal X} r \\log g(\\mathbf x \\mid \\theta) + (1-r) \\log (1 - g(\\mathbf x \\mid \\theta)) $\n",
    "* $g(\\mathbf x \\mid \\mathbf w, w_0) = \\frac{1}{1 + \\exp{-(\\mathbf w \\cdot \\mathbf x + w_0)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Using sklearn \n",
    "```python   \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression().fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pos = np.random.multivariate_normal([0, 0.3], \n",
    "                                    [[0.3, 0.1], [0.1, 0.3]], size=100)\n",
    "neg = np.random.multivariate_normal([2.3, -0.3], \n",
    "                                    [[0.1, 0.01], [0.01, 0.3]], size=100)\n",
    "X = np.concatenate((pos, neg))\n",
    "y = np.zeros(pos.shape[0] + neg.shape[0])\n",
    "y[:pos.shape[0]] = 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression().fit(X, y)\n",
    "m_bayes = GaussianNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 4, 1000)\n",
    "y = np.linspace(-2, 2, 1000)\n",
    "\n",
    "pylab.plot([x[0] for x in pos], [x[1] for x in pos], '*')\n",
    "pylab.plot([x[0] for x in neg], [x[1] for x in neg], '*')\n",
    "pylab.ylim(-2, 2)\n",
    "pylab.xlim(-2, 4)\n",
    "\n",
    "px, py = boundary(x, y, m)\n",
    "pylab.ylim(-2, 2)\n",
    "pylab.xlim(-2, 4)\n",
    "pylab.plot(px, py, '+')\n",
    "px, py = boundary(x, y, m_bayes)\n",
    "pylab.plot(px, py, '+')\n",
    "pylab.legend(['Positiva', 'Negativa', 'Logistic', 'GaussianNB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Tres clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "centers = [(-5, -5), (0, 0), (5, 5)]\n",
    "X, y = make_blobs(n_samples=300, n_features=2, cluster_std=1.0,\n",
    "                  centers=centers, shuffle=False, random_state=42)\n",
    "for k in np.unique(y):\n",
    "    pylab.plot(X[y == k, 0], X[y == k, 1], '.')\n",
    "# pylab.legend(['Clase 1', 'Clase 2', 'Clase 3'])\n",
    "m = LogisticRegression().fit(X, y)\n",
    "px, py = boundary(np.linspace(-8, 10, 1000), np.linspace(-8, 8, 1000), m)\n",
    "pylab.plot(px, py, '+')\n",
    "m = GaussianNB().fit(X, y)\n",
    "px, py = boundary(np.linspace(-8, 10, 1000), np.linspace(-8, 8, 1000), m)\n",
    "pylab.plot(px, py, '+')\n",
    "# pylab.legend(['Clase 1', 'Clase 2', 'Clase 3', 'Logistic', 'GaussianNB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dos clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "centers = [(-5, -5), (0, 0), (5, 5)]\n",
    "X, y = make_blobs(n_samples=300, n_features=2, cluster_std=1.0,\n",
    "                  centers=centers, shuffle=False, random_state=42)\n",
    "y[-100:] = 0\n",
    "for k in np.unique(y):\n",
    "    pylab.plot(X[y == k, 0], X[y == k, 1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for k in np.unique(y):\n",
    "    pylab.plot(X[y == k, 0], X[y == k, 1], '.')\n",
    "# pylab.legend(['Clase 1', 'Clase 2', 'Clase 3'])\n",
    "m = LogisticRegression().fit(X, y)\n",
    "px, py = boundary(np.linspace(-8, 10, 1000), np.linspace(-8, 8, 1000), m)\n",
    "pylab.plot(px, py, '+')\n",
    "m = GaussianNB().fit(X, y)\n",
    "px, py = boundary(np.linspace(-8, 10, 1000), np.linspace(-8, 8, 1000), m)\n",
    "pylab.plot(px, py, '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from EvoDAG.model import EvoDAGE\n",
    "m = EvoDAGE().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Usando EvoDAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for k in np.unique(y):\n",
    "    pylab.plot(X[y == k, 0], X[y == k, 1], '.')\n",
    "px, py = boundary(np.linspace(-8, 10, 100), np.linspace(-8, 8, 100), m)\n",
    "pylab.plot(px, py, '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "from EvoDAG.model import EvoDAGE\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "centers = [(-5, -5), (0, 0), (5, 5), (10, 10)]\n",
    "X, y = make_blobs(n_samples=400, n_features=2, cluster_std=1.0,\n",
    "                  centers=centers, shuffle=False, random_state=42)\n",
    "y[200:300] = 0\n",
    "y[300:] = 1\n",
    "for k in np.unique(y):\n",
    "    pylab.plot(X[y == k, 0], X[y == k, 1], '.')\n",
    "# pylab.legend(['Clase 1', 'Clase 2', 'Clase 3'])\n",
    "m = GaussianNB().fit(X, y)\n",
    "px, py = boundary(np.linspace(-10, 15, 1000), np.linspace(-10, 15, 1000), m)\n",
    "pylab.plot(px, py, '.')\n",
    "m = EvoDAGE().fit(X, y)\n",
    "px, py = boundary(np.linspace(-10, 15, 100), np.linspace(-10, 15, 100), m)\n",
    "pylab.plot(px, py, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regresión\n",
    "\n",
    "* Enfocados a clasificación binaria y multi-clase\n",
    "* Variable dependiente es  \n",
    "  $r \\in \\mathbb R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Se busca $h: \\mathbf x \\rightarrow \\mathbb R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "y = np.sin(x) + np.sqrt(np.fabs(x))\n",
    "pylab.plot(x, y, '.')\n",
    "pylab.legend(['f(x)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Regresión lineal\n",
    "* Sea $A$ las observaciones\n",
    "* $A \\equiv (\\mathbf x_1, \\mathbf x_2, \\cdots, \\mathbf x_N)$\n",
    "* $A \\mathbf w = r$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\mathbf w = A^{-1} r$\n",
    "* $A$ por lo general no es invertible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $A^\\prime A \\mathbf w = A^{\\prime} r$\n",
    "* $\\mathbf w = (A^\\prime A)^{-1} A^{\\prime} r$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Minimos Cuadrados Ordinarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "D = np.vstack((x, np.ones(x.shape[0]))).T\n",
    "coef = np.linalg.lstsq(D, y)[0]\n",
    "pylab.plot(x, y, '.')\n",
    "pylab.plot(x, np.dot(D, coef), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "D = np.vstack((x, x**2, x**3, np.ones(x.shape[0]))).T\n",
    "coef = np.linalg.lstsq(D, y)[0]\n",
    "pylab.plot(x, y, '.')\n",
    "pylab.plot(x, np.dot(D, coef), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from EvoDAG.model import EvoDAGE\n",
    "m = EvoDAGE(classifier=False).fit(np.atleast_2d(x).T, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# EvoDAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pylab.plot(x, y, '.')\n",
    "pylab.plot(x, m.predict(np.atleast_2d(x).T), '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Actividad\n",
    "\n",
    "* Graficar la función de decisión de un clasificador entrenado como un problema de regresión\n",
    "* Utilizar Basis functions con Regresión Logística en el problema que falló\n",
    "* Encontrar una función que aproxime los datos de regresión\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "3-Metodos-Parametricos.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
