{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aprendizaje Computacional  \n",
    "\n",
    "## Mario Graff (mgraffg@ieee.org, mario.graff@infotec.mx)  \n",
    "## [https://github.com/ingeotec](https://github.com/ingeotec)\n",
    "## [https://github.com/mgraffg](https://github.com/mgraffg)\n",
    "## CONACYT - INFOTEC  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Temas\n",
    "\n",
    "1. Introducción\n",
    "2. Aprendizaje supervisado\n",
    "3. Métodos paramétricos\n",
    "4. Métodos no-paramétricos\n",
    "5. Máquinas de kernel\n",
    "6. Métodos no convencionales de aprendizaje\n",
    "7. Diseño y análisis de experimentos de aprendizaje\n",
    "8. Aplicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparación de algoritmos\n",
    "\n",
    "* Se tiene $k$ algoritmos\n",
    "* ¿Quién es el mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* El que entrena mejor - $\\mathcal X$\n",
    "* El que generaliza mejor - $\\mathcal P$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Dividir $\\mathcal X$ en dos conjuntos\n",
    "* $\\mathcal X$ y $\\mathcal P$\n",
    "* Estratificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creación de $\\mathcal X$ y $\\mathcal P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "wine = datasets.load_wine()\n",
    "mask = np.random.binomial(1, 0.7,\n",
    "                          size=wine.data.shape[0]).astype(np.bool)\n",
    "train = wine.data[mask]\n",
    "test = wine.data[~mask]\n",
    "test_target = wine.target[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Rendimiento de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "linear = LinearSVC().fit(train, wine.target[mask]).predict(test)\n",
    "logistic = LogisticRegression().fit(train, wine.target[mask]).predict(test)\n",
    "naive = GaussianNB().fit(train, wine.target[mask]).predict(test)\n",
    "print(accuracy_score(test_target, linear),\n",
    "      accuracy_score(test_target, logistic),\n",
    "      accuracy_score(test_target, naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# ¿Quién es mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(30):\n",
    "    mask = np.random.binomial(1, 0.7, size=wine.data.shape[0]).astype(np.bool)\n",
    "    train = wine.data[mask]\n",
    "    test = wine.data[~mask]\n",
    "    test_target = wine.target[~mask]\n",
    "    linear = LinearSVC().fit(train, wine.target[mask]).predict(test)\n",
    "    logistic = LogisticRegression().fit(train, wine.target[mask]).predict(test)\n",
    "    naive = GaussianNB().fit(train, wine.target[mask]).predict(test)\n",
    "    _ = [accuracy_score(test_target, linear), accuracy_score(test_target, logistic),\n",
    "         accuracy_score(test_target, naive)]\n",
    "    res.append(_)\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "hist(res[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "np.mean(res, axis=0), stats.sem(res, axis=0) * 1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# KFold\n",
    "\n",
    "* Dividir $\\mathcal X$ en $k$ conjuntos\n",
    "* $\\bigcap_i^k \\mathcal X_i = \\emptyset$\n",
    "* Generar $k$ pares de ($\\mathcal X$, $\\mathcal P$)\n",
    "* $A_1 = \\mathcal X_1, \\ldots, \\mathcal X_{k-1}$\n",
    "* $B_1 = \\mathcal X_{k}$\n",
    "* $A_2 = \\mathcal X_1, \\ldots, \\mathcal X_{k-2}, \\mathcal X_{k}$\n",
    "* $B_2 = \\mathcal X_{k-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "res = []\n",
    "kf = model_selection.KFold(n_splits=30, random_state=0, shuffle=True)\n",
    "for ts, vs in kf.split(wine.data):\n",
    "    train = wine.data[ts]\n",
    "    test = wine.data[vs]\n",
    "    test_target = wine.target[vs]\n",
    "    linear = LinearSVC().fit(train, wine.target[ts]).predict(test)\n",
    "    logistic = LogisticRegression().fit(train, wine.target[ts]).predict(test)\n",
    "    naive = GaussianNB().fit(train, wine.target[ts]).predict(test)\n",
    "    _ = [accuracy_score(test_target, linear), accuracy_score(test_target, logistic),\n",
    "         accuracy_score(test_target, naive)]\n",
    "    res.append(_)\n",
    "res = np.array(res)\n",
    "np.mean(res, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Diferencias en rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "kruskal(res[:, 0], res[:, 1], res[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Comparación de dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "wilcoxon(res[:, 0], res[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Comparación de $k$ algoritmos contra el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EvoMSA.command_line import CommandLinePerformance\n",
    "CommandLinePerformance.compute_p(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Medidas de rendimiento para clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# _Accuracy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "target = np.random.randint(0, 3, size=100)\n",
    "hy = np.random.randint(0, 3, size=100)\n",
    "np.mean(target == hy), accuracy_score(target, hy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# ¿Qué tan bueno es el _accuracy_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.zeros(100)\n",
    "target[-10:] = 1\n",
    "hy = np.zeros(100)\n",
    "np.mean(target == hy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# _Recall_\n",
    "\n",
    "* Usado en recuperación de información\n",
    "* Del total de objetos buscados ¿Cuál es la proporción que recuperaste?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "def recall(target, hy):\n",
    "    res = []\n",
    "    for k in np.unique(target):\n",
    "        m = (hy == k) & (target == k)\n",
    "        res.append(m.sum() / (target == k).sum())\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(target, hy, average=None))\n",
    "print(recall(target, hy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.binomial(1, 0.7, size=wine.data.shape[0]).astype(np.bool)\n",
    "train = wine.data[mask]\n",
    "test = wine.data[~mask]\n",
    "test_target = wine.target[~mask]\n",
    "linear = LinearSVC().fit(train, wine.target[mask]).predict(test)\n",
    "print(recall_score(test_target, linear, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall(test_target, naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Precision\n",
    "\n",
    "* La proporción de ejemplos correctamente etiquetados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = np.zeros(100)\n",
    "target[50:] = 1\n",
    "hy = np.ones(100)\n",
    "hy[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(target, hy), recall_score(target, hy, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(target, hy):\n",
    "    res = []\n",
    "    for k in np.unique(target):\n",
    "        mask = hy == k\n",
    "        res.append((target[mask] == k).sum() / mask.sum())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(target, hy, average=None), precision(target, hy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(test_target, naive, average=None), precision(test_target, naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1\n",
    "\n",
    "* Media armónica entre _recall_ y _precision_\n",
    "* $2 \\frac{p \\cdot r}{p + r}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(target, hy, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Macro\n",
    "\n",
    "* Macro-recall\n",
    "* Macro-precision\n",
    "* Macro-F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(target, hy, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC\n",
    "\n",
    "* Area bajo la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import datasets\n",
    "bc= datasets.load_breast_cancer()\n",
    "mask = np.random.binomial(1, 0.7, size=bc.data.shape[0]).astype(np.bool)\n",
    "train = bc.data[mask]\n",
    "test = bc.data[~mask]\n",
    "test_target = bc.target[~mask]\n",
    "m = GaussianNB().fit(train, bc.target[mask])\n",
    "df = m.predict_proba(test)\n",
    "fpr, tpr, _ = roc_curve(test_target, df[:, 1] - df[:, 0])\n",
    "plot(fpr, tpr)\n",
    "plot([0, 1], [0, 1], color='navy', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
